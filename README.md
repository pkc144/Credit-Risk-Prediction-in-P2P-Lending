
---

### âœ… Final `README.md` (No License Section)

```markdown
# ğŸ§  Credit Risk Prediction using SHAP and Hybrid Feature Selection

This project presents an end-to-end machine learning pipeline to predict credit risk using ensemble models and explainable AI (SHAP).  
It is part of the B.Tech major project titled:

**â€œImproving Default Prediction in Peer-to-Peer Lending with Feature Selection and Explainable ML Modelsâ€**  
ğŸ“ Department of Computer Science, NIT Karnataka

---

## ğŸ“ Project Structure

```

CREDIT-RISK/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Trainset.csv
â”œâ”€â”€ models/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ Auc\_curves/
â”‚   â”œâ”€â”€ confusion\_matrix/
â”‚   â”œâ”€â”€ evaluation\_metrics/
â”‚   â””â”€â”€ top\_15\_features/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Train/
â”‚   â”‚   â”œâ”€â”€ catboost\_basic.py
â”‚   â”‚   â”œâ”€â”€ catboost\_shap.py
â”‚   â”‚   â”œâ”€â”€ catboost\_shap\_union.py
â”‚   â”‚   â”œâ”€â”€ decision\_tree\_basic.py
â”‚   â”‚   â”œâ”€â”€ decision\_tree\_shap.py
â”‚   â”‚   â”œâ”€â”€ decision\_tree\_shap\_union.py
â”‚   â”‚   â”œâ”€â”€ gradient\_boost\_basic.py
â”‚   â”‚   â”œâ”€â”€ gradient\_boost\_shap.py
â”‚   â”‚   â”œâ”€â”€ gradient\_boost\_shap\_union.py
â”‚   â”‚   â”œâ”€â”€ lightgbm\_basic.py
â”‚   â”‚   â”œâ”€â”€ lightgbm\_shap.py
â”‚   â”‚   â”œâ”€â”€ lightgbm\_shap\_union.py
â”‚   â”‚   â”œâ”€â”€ random\_forest\_basic.py
â”‚   â”‚   â”œâ”€â”€ random\_forest\_shap.py
â”‚   â”‚   â”œâ”€â”€ random\_forest\_shap\_union.py
â”‚   â”‚   â”œâ”€â”€ xgboost\_basic.py
â”‚   â”‚   â”œâ”€â”€ xgboost\_shap.py
â”‚   â”‚   â”œâ”€â”€ xgboost\_shap\_union.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

````

---

## ğŸš€ Highlights

- âœ… SHAP-based interpretability for every model
- âœ… Hybrid feature selection: SHAP + model-based
- ğŸ” Models implemented: XGBoost, LightGBM, Random Forest, CatBoost, Gradient Boost, Decision Tree
- âš¡ Each model trained in 3 versions: `basic`, `shap`, `shap + union`
- ğŸ“Š Outputs include: AUC curves, confusion matrices, feature importance

---

## ğŸ’» How to Run

### 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
````

### 2ï¸âƒ£ Run Preprocessing

```bash
python src/preprocessing.py
```

### 3ï¸âƒ£ Train Any Model (Examples)

```bash
# XGBoost
python src/Train/xgboost_basic.py
python src/Train/xgboost_shap.py
python src/Train/xgboost_shap_union.py

# LightGBM
python src/Train/lightgbm_basic.py
python src/Train/lightgbm_shap.py
python src/Train/lightgbm_shap_union.py

# Random Forest
python src/Train/random_forest_basic.py
python src/Train/random_forest_shap.py
python src/Train/random_forest_shap_union.py

# CatBoost
python src/Train/catboost_basic.py
python src/Train/catboost_shap.py
python src/Train/catboost_shap_union.py

# Gradient Boost
python src/Train/gradient_boost_basic.py
python src/Train/gradient_boost_shap.py
python src/Train/gradient_boost_shap_union.py

# Decision Tree
python src/Train/decision_tree_basic.py
python src/Train/decision_tree_shap.py
python src/Train/decision_tree_shap_union.py
```

### 4ï¸âƒ£ Evaluate Results

```bash
python src/evaluate.py
```

### 5ï¸âƒ£ Check Outputs

All results are saved inside the `outputs/` folder:

* Confusion matrices
* AUC curves
* SHAP plots
* Evaluation metric tables
* Top 15 features (text)

---

## ğŸ§ª Output Samples

### ğŸ“Š Evaluation Table

![Evaluation Table](outputs/evaluation_metrics/evaluation_metrics_table.png)

### ğŸŒ€ Confusion Matrix Example

![Confusion Matrix](outputs/confusion_matrix/xgboost_confusion_matrix.png)

---

## ğŸ“š Requirements

Common packages used (in `requirements.txt`):

* `scikit-learn`
* `xgboost`, `lightgbm`, `catboost`
* `shap`
* `matplotlib`, `seaborn`, `pandas`, `numpy`

---

## ğŸ™‹â€â™‚ï¸ Author

**Prince Kumar Chaudhary**
ğŸ“ B.Tech â€“ Computer Science, NITK Surathkal
